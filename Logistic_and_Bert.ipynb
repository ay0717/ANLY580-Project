{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import string\n",
    "import unicodedata\n",
    "import html\n",
    "from html.parser import HTMLParser\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.util import  mark_negation\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report as clsr\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torchtext import data\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_reviews=pd.DataFrame()\n",
    "for stance in os.listdir('./op_spam_v1.4'):\n",
    "    negative_path=os.listdir('./op_spam_v1.4/'+stance)\n",
    "    for val in negative_path:\n",
    "        for i in range(1,6):\n",
    "            next_path='./op_spam_v1.4/'+stance+'/'+val+'/'+'fold'+str(i)\n",
    "            file_names=os.listdir(next_path)\n",
    "            content=[]\n",
    "            hotel_name=[]\n",
    "            for name in file_names:\n",
    "                full_path=next_path+'/'+name\n",
    "                next_name=name.split('_')[1]\n",
    "                hotel_name.append(next_name)\n",
    "                with open (full_path,'r') as myfile:\n",
    "                    content.append(myfile.read())\n",
    "            file_amount=len(file_names)\n",
    "            val_label=file_amount*[val.split('_')[0]]\n",
    "            stance_label=file_amount*[stance.split('_')[0]]\n",
    "            resource=[val.split('_')[2]]*file_amount\n",
    "            next_dict={'Resource':resource,'Hotel':hotel_name,'Review':content,'Stance':stance_label,'Authenticity':val_label}\n",
    "            next_df=pd.DataFrame(next_dict)\n",
    "            hotel_reviews=pd.concat([hotel_reviews,next_df],axis=0)\n",
    "    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>Hotel</th>\n",
       "      <th>Review</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Authenticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>We stayed at the Schicago Hilton for 4 days an...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>Hotel is located 1/2 mile from the train stati...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>I made my reservation at the Hilton Chicago be...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>When most people think Hilton, they think luxu...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>My husband and I recently stayed stayed at the...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Resource   Hotel                                             Review  \\\n",
       "0    MTurk  hilton  We stayed at the Schicago Hilton for 4 days an...   \n",
       "1    MTurk  hilton  Hotel is located 1/2 mile from the train stati...   \n",
       "2    MTurk  hilton  I made my reservation at the Hilton Chicago be...   \n",
       "3    MTurk  hilton  When most people think Hilton, they think luxu...   \n",
       "4    MTurk  hilton  My husband and I recently stayed stayed at the...   \n",
       "\n",
       "     Stance Authenticity  \n",
       "0  negative    deceptive  \n",
       "1  negative    deceptive  \n",
       "2  negative    deceptive  \n",
       "3  negative    deceptive  \n",
       "4  negative    deceptive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the row dataframe that we wanted, with those attributes(hotel name, sentiment polarity, resource, review and a label(authenticity))! We can move the next step which is cleaning and tokenizing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build a preprocessor first tokenize the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "    def __init__(self, lower=True, strip=True, remove_punct=True, remove_diacritics=True, unicode_form='NFC', remove_stop=False, stem_tokens=False, lemmatize_tokens=True, language='english'):\n",
    "        \n",
    "        self.lower      = lower\n",
    "        self.strip      = strip\n",
    "        self.remove_punct = remove_punct\n",
    "        self.remove_diacritics = remove_diacritics\n",
    "        self.set_unicode_form(unicode_form)\n",
    "     \n",
    "        self.remove_stop = remove_stop\n",
    "        self.stem_tokens = stem_tokens\n",
    "        self.lemmatize_tokens = lemmatize_tokens    \n",
    "\n",
    "        self.stopwords  = set(nltk.corpus.stopwords.words(language))\n",
    "        self.punct      = set(string.punctuation)\n",
    "\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stemmer = nltk.stem.SnowballStemmer(language) \n",
    "        self.tokenizer = TweetTokenizer()\n",
    "\n",
    " \n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            list(self.tokenize(doc)) for doc in X\n",
    "        ]\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return [\" \".join(doc) for doc in X]\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    " \n",
    "    def set_stopwords(self, stopwords):\n",
    "        self.stopwords  = stopwords or set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "\n",
    "    def set_punct(self, punct):\n",
    "        self.punct      = punct or set(string.punctuation)\n",
    "\n",
    "\n",
    "    def set_unicode_form(self, unicode_form):\n",
    "        self.unicode_form = unicode_form.strip().upper()\n",
    "        if not self.unicode_form in ['NFC','NFD','NFKC','NFKD']:\n",
    "            self.unicode_form = 'NFC'\n",
    "\n",
    "\n",
    "    def show_settings(self):\n",
    "        print(\"lower: \",self.lower)\n",
    "        print(\"strip: \",self.strip)\n",
    "        print(\"remove_punct: \",self.remove_punct)\n",
    "        print(\"remove_diacritics: \",self.remove_diacritics)\n",
    "        print(\"unicode_form: \",self.unicode_form)\n",
    "        print(\"remove_stop: \",self.remove_stop)\n",
    "        print(\"stem_tokens: \",self.stem_tokens)\n",
    "        print(\"lemmatize_tokens\",self.lemmatize_tokens)       \n",
    "        print(\"lemmatizer: \",type(self.lemmatizer).__name__)\n",
    "        print(\"stemmer: \",type(self.stemmer).__name__) \n",
    "        print(\"punctuation: \",self.punct)\n",
    "        print(\"stopwords: \",self.stopwords)\n",
    "\n",
    "\n",
    "    # convert nltk pos-tag to wordnet pos-tag\n",
    "    # for use by the wordnet lemmatizer\n",
    "    @staticmethod\n",
    "    def get_wordnet_tag(nltk_tag):\n",
    "        if nltk_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        elif nltk_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:          \n",
    "            return None\n",
    "\n",
    "    # determine whether a string is comprised of all punctuation-like characters\n",
    "    def is_punct(self, text):\n",
    "        if text in self.punctuation:\n",
    "            return True\n",
    "        if regex.match(r\"[\\p{P}\\p{Mn}\\p{Sk}]+\", text):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    # normalize token strings\n",
    "    def normalize_string(self, token):\n",
    "\n",
    "        token = html.unescape(token)\n",
    "        token = token.lower() if self.lower else token\n",
    "        token = token.strip(' _*')  if self.strip else token\n",
    "\n",
    "        if self.remove_diacritics:\n",
    "            token = regex.sub(\"\\p{Mn}\",'',unicodedata.normalize('NFD',token)) \n",
    "\n",
    "        #not is in the stopword list, but n't isn'\n",
    "        if token == \"n't\" and self.stopwords:\n",
    "            token = \"not\"\n",
    "      \n",
    "        return unicodedata.normalize(self.unicode_form,token)\n",
    "\n",
    "    # determine whether a string is comprised completely\n",
    "    # of things that seem like punctuation\n",
    "    def is_punct(self, text):\n",
    "        if text in string.punctuation:\n",
    "            return True\n",
    "        if regex.match(r\"^[\\p{P}\\p{Mn}\\p{Sk}]+$\", text):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # tokenize the document with optional normalization\n",
    "    def tokenize(self, document, all_fields=False):\n",
    "        tokens = []\n",
    "        for sent in sent_tokenize(document):\n",
    "            cleaner_sent = html.unescape(sent)\n",
    "            for token in nltk.pos_tag(self.tokenizer.tokenize(cleaner_sent)):\n",
    "                stem = ''\n",
    "                token_text = self.normalize_string(token[0])\n",
    "                token_pos = token[1]\n",
    "                if self.remove_punct and self.is_punct(token_text):\n",
    "                #if remove_punct and token_text in string.punctuation:\n",
    "                    continue\n",
    "                if self.remove_stop and token_text in self.stopwords:\n",
    "                    continue\n",
    "                if self.stem_tokens or all_fields:\n",
    "                    stem = self.stemmer.stem(token_text)\n",
    "                if self.lemmatize_tokens or all_fields:\n",
    "                    wordnet_tag = self.get_wordnet_tag(token_pos)\n",
    "                    if wordnet_tag is not None:\n",
    "                        lemma = self.lemmatizer.lemmatize(token_text,wordnet_tag)\n",
    "                    else:\n",
    "                        lemma = token_text\n",
    "                if all_fields:\n",
    "                    tokens.append({'token': token_text, 'stem': stem, 'lemma': lemma})\n",
    "                elif self.stem_tokens:\n",
    "                    tokens.append(stem)\n",
    "                elif self.lemmatize_tokens:\n",
    "                    tokens.append(lemma)\n",
    "                else:\n",
    "                    tokens.append(token_text)     \n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the preprocessor to tokenize the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>Hotel</th>\n",
       "      <th>Review</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Authenticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>[stay, schicago, hilton, 4, day, 3, night, con...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>[hotel, locate, 1/2, mile, train, station, qui...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>[make, reservation, hilton, chicago, believe, ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>[people, think, hilton, think, luxury, know, w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>[husband, recently, stay, stay, hilton, chicag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Resource   Hotel                                             Review  \\\n",
       "0    MTurk  hilton  [stay, schicago, hilton, 4, day, 3, night, con...   \n",
       "1    MTurk  hilton  [hotel, locate, 1/2, mile, train, station, qui...   \n",
       "2    MTurk  hilton  [make, reservation, hilton, chicago, believe, ...   \n",
       "3    MTurk  hilton  [people, think, hilton, think, luxury, know, w...   \n",
       "4    MTurk  hilton  [husband, recently, stay, stay, hilton, chicag...   \n",
       "\n",
       "     Stance Authenticity  \n",
       "0  negative    deceptive  \n",
       "1  negative    deceptive  \n",
       "2  negative    deceptive  \n",
       "3  negative    deceptive  \n",
       "4  negative    deceptive  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_preprocessor = Preprocessor(remove_punct=True, remove_stop=True, lemmatize_tokens=True)\n",
    "hotel_reviews['Review']=hotel_reviews['Review'].apply(my_preprocessor.tokenize)\n",
    "hotel_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the data type of the columns in this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resource        object\n",
       "Hotel           object\n",
       "Review          object\n",
       "Stance          object\n",
       "Authenticity    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_reviews.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change our label to category type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_reviews['Authenticity']=hotel_reviews['Authenticity'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we split the dataframe into train and test data, I will save it to a csv file firstly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_reviews.to_csv('Hotel_reviews.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_reviews = pd.read_csv('Hotel_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>Hotel</th>\n",
       "      <th>Review</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Authenticity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>['stay', 'schicago', 'hilton', '4', 'day', '3'...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>['hotel', 'locate', '1/2', 'mile', 'train', 's...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>['make', 'reservation', 'hilton', 'chicago', '...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>['people', 'think', 'hilton', 'think', 'luxury...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MTurk</td>\n",
       "      <td>hilton</td>\n",
       "      <td>['husband', 'recently', 'stay', 'stay', 'hilto...</td>\n",
       "      <td>negative</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Resource   Hotel                                             Review  \\\n",
       "0    MTurk  hilton  ['stay', 'schicago', 'hilton', '4', 'day', '3'...   \n",
       "1    MTurk  hilton  ['hotel', 'locate', '1/2', 'mile', 'train', 's...   \n",
       "2    MTurk  hilton  ['make', 'reservation', 'hilton', 'chicago', '...   \n",
       "3    MTurk  hilton  ['people', 'think', 'hilton', 'think', 'luxury...   \n",
       "4    MTurk  hilton  ['husband', 'recently', 'stay', 'stay', 'hilto...   \n",
       "\n",
       "     Stance Authenticity  \n",
       "0  negative    deceptive  \n",
       "1  negative    deceptive  \n",
       "2  negative    deceptive  \n",
       "3  negative    deceptive  \n",
       "4  negative    deceptive  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_reviews['Review'] = hotel_reviews['Review'].apply(lambda x: ' '.join(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=hotel_reviews['Review']\n",
    "labels=hotel_reviews['Authenticity']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels \\\n",
    "    = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_sparse_matrix = tfidf_vectorizer.fit_transform(train_texts)\n",
    "test_tfidf_sparse_matrix = tfidf_vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(train_tfidf_sparse_matrix, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_labels = clf.predict(test_tfidf_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.865625\n",
      "Precision: 0.8671131128758247\n",
      "Recall: 0.8638784461152882\n",
      "Macro F1: 0.8647998034880864\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(test_labels, pred_test_labels))\n",
    "print(\"Precision:\", precision_score(test_labels, pred_test_labels, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(test_labels, pred_test_labels, average=\"macro\"))\n",
    "print(\"Macro F1:\", f1_score(test_labels, pred_test_labels, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(test_labels, pred_test_labels, labels=['deceptive', 'truthful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[151  17]\n",
      " [ 26 126]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['deceptive', 'truthful'], \n",
    "                      title='Logistic Regression Classifier: \\nConfusion matrix for Deceptive Opinion Spam Detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_int = list(map(lambda x: label_to_index[x], test_labels.tolist()))\n",
    "pred_test_labels_int = list(map(lambda x: label_to_index[x], pred_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   deceptive       0.85      0.90      0.88       168\n",
      "    truthful       0.88      0.83      0.85       152\n",
      "\n",
      "    accuracy                           0.87       320\n",
      "   macro avg       0.87      0.86      0.86       320\n",
      "weighted avg       0.87      0.87      0.87       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report as clsr\n",
    "print(clsr(test_labels_int, pred_test_labels_int, target_names=['deceptive', 'truthful']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used another supervised learning model logistic regression to classify authenticity. For logistic regression model, we take the processed textual data and transform to TF-IDF vectors as the input data. The model achieved an accuracy of 86.6%, precision of 86.7%, recall of 86.4%, and f1 score of 86.4%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=hotel_reviews['Review']\n",
    "labels=hotel_reviews['Authenticity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = {}\n",
    "index_to_label = {}\n",
    "label_lst = list(set(labels))\n",
    "for i in range(len(label_lst)):\n",
    "    label = label_lst[i]\n",
    "    label_to_index[label] = i\n",
    "    index_to_label[i] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "for text in texts:\n",
    "    encoded_sent = tokenizer.encode(text,\n",
    "                                    add_special_tokens=True, \n",
    "                                    max_length=128,\n",
    "                                    truncation=True)\n",
    "    input_ids.append(encoded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  128\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sent) for sent in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences(input_ids, maxlen=128, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [label_to_index[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, test_input_ids, train_labels, test_labels \\\n",
    "    = train_test_split(input_ids, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_attention_masks, test_attention_masks, train_labels, test_labels \\\n",
    "    = train_test_split(attention_masks, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = torch.tensor(train_input_ids)\n",
    "test_input_ids = torch.tensor(test_input_ids)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_attention_masks = torch.tensor(train_attention_masks)\n",
    "test_attention_masks = torch.tensor(test_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels = len(label_lst),  \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False\n",
    ")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 GPU(s) available.\n",
      "We will use the GPU: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(6))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training...\n",
      "Average training loss: 0.62\n",
      "\n",
      "Epoch 2\n",
      "Training...\n",
      "Average training loss: 0.42\n",
      "\n",
      "Epoch 3\n",
      "Training...\n",
      "Average training loss: 0.29\n",
      "\n",
      "Epoch 4\n",
      "Training...\n",
      "Average training loss: 0.15\n",
      "\n",
      "Epoch 5\n",
      "Training...\n",
      "Average training loss: 0.08\n",
      "\n",
      "Epoch 6\n",
      "Training...\n",
      "Average training loss: 0.06\n",
      "\n",
      "Epoch 7\n",
      "Training...\n",
      "Average training loss: 0.07\n",
      "\n",
      "Epoch 8\n",
      "Training...\n",
      "Average training loss: 0.02\n",
      "\n",
      "Epoch 9\n",
      "Training...\n",
      "Average training loss: 0.01\n",
      "\n",
      "Epoch 10\n",
      "Training...\n",
      "Average training loss: 0.01\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(10):\n",
    "    print(\"\")\n",
    "    print('Epoch {}'.format(epoch_i + 1))\n",
    "    print('Training...')\n",
    "    \n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds_test = []\n",
    "labels_test = []\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    preds_flat = np.argmax(logits, axis=1).flatten()\n",
    "    labels_flat = label_ids.flatten()\n",
    "    \n",
    "    preds_test += list(preds_flat)\n",
    "    labels_test += list(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.846875\n",
      "Precision: 0.849616439445129\n",
      "Recall: 0.8444548872180451\n",
      "Macro F1: 0.8456069870715546\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(labels_test, preds_test))\n",
    "print(\"Precision:\", precision_score(labels_test, preds_test, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(labels_test, preds_test, average=\"macro\"))\n",
    "print(\"Macro F1:\", f1_score(labels_test, preds_test, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_txt = list(map(lambda x: index_to_label[x], labels_test))\n",
    "preds_test_txt = list(map(lambda x: index_to_label[x], preds_test))\n",
    "cnf_matrix = confusion_matrix(labels_test_txt, preds_test_txt, labels=['deceptive', 'truthful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[150  18]\n",
      " [ 31 121]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.grid(False)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['deceptive', 'truthful'], \n",
    "                      title='BERT Classifier: \\nConfusion matrix for Deceptive Opinion Spam Detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   deceptive       0.83      0.89      0.86       168\n",
      "    truthful       0.87      0.80      0.83       152\n",
      "\n",
      "    accuracy                           0.85       320\n",
      "   macro avg       0.85      0.84      0.85       320\n",
      "weighted avg       0.85      0.85      0.85       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clsr(labels_test, preds_test, target_names=['deceptive', 'truthful']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also used BERT which is a transformer-based machine learning model for our classification problem. For BERT model, it is different from logistic regression. We pass in the textual data and BERT will tokenize the texts by inserting some tokens to indicate the start and end of the sentence. BERT will also use mask to separate different sentences. Each token will be mapped to a token id. Position embeddings are also added to indicate the position of each token. After tokenizing the input, the token ids as well as the attention masks will be fed into classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the evaluation on the test set, we can observe that BERT model is slightly better than logistic regression and Naive Bayes, but not as good as SVM. This could be because that the dataset is not a complex task. For more complex tasks, BERT model can be expected to perform better. But overall, all the models we trained made pretty accurate predictions on this dataset.\n",
    "\n",
    "In the future, we could improve by incorporating word2vec embeddings instead of using TF-IDF and\n",
    "count vectorizers, or include more feature engineering techniques before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
